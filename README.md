<h1 align="center" style="font-weight: bold;">Scraping Google Reviews ğŸ’»</h1>
<p align="center">
  <img src="https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white"></img>
  <img src="https://img.shields.io/badge/Puppeteer-white.svg?style=for-the-badge&logo=Puppeteer&logoColor=black"></img>
  <img src="https://img.shields.io/badge/DJANGO-REST-ff1709?style=for-the-badge&logo=django&logoColor=white&color=ff1709&labelColor=gray"></img>
  <img src="https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white"></img>
</p>
<p align="center">
 <a href="#tech">Tecnologias usadas</a> â€¢ 
 <a href="#intro">IntroduÃ§Ã£o</a> â€¢ 
 <a href="#projec-actors">Autores</a>
</p>
<p align="center">
    <b>Um projeto que faz scraping do Google Reviews automaticamente com serviÃ§os AWS.</b>
</p>


<h2 id="tech">ğŸ“¦ Tecnologias usadas:</h2>

- [Django](https://www.djangoproject.com/)
- [Django REST Framework](https://www.django-rest-framework.org/)
- [Axios](https://axios-http.com/)
- [Puppeteer](https://pptr.dev/)
- [Moment](https://momentjs.com/)
- **ServiÃ§os AWS:**
  - [AWS Lambda](https://docs.aws.amazon.com/lambda/)
  - [AWS SQS](https://docs.aws.amazon.com/sqs/)
  - [AWS RDS](https://docs.aws.amazon.com/rds/)

<h2 id="intro">ğŸ”¥ IntroduÃ§Ã£o:</h2>

<h3>âš™ï¸ PrÃ©-requisitos:</h3>

VocÃª precisa ter instalado na sua mÃ¡quina as seguintes tecnologias nas exatas versÃµes apontadas abaixo:
- Serverless Framework V4
- Node 20.x
- Python 3.12

*Obs.: Se quiser, vocÃª pode usar o Node ou o Python em versÃµes diferentes, mas, lembre-se de ajustar a versÃ£o no serverless.yml dos microserviÃ§os. AlÃ©m disto, dependendo de qual versÃ£o serÃ¡ utilizada, avalie se nÃ£o precisa alterar algo no cÃ³digo.

<h3>ğŸ”¨ Guia de instalaÃ§Ã£o:</h3>

Para instalar este projeto, acesse [este link](https://github.com/EmanuelLacerda/scraping-google-reviews/blob/main/installation-guide.md) ou acesse o arquivo "installation-guide.md" presente na raiz deste repositÃ³rio.

ApÃ³s instalar o projeto, vocÃª nÃ£o precisa executa ele, pois ele funciona de maneira automÃ¡tica. VocÃª apenas precisa adicionar os business que devem passar pelo scraping. Vejo o tÃ³pico "API Endpoints" para saber qual endpoint utilizar para fazer esta adiÃ§Ã£o.

<h2 id="projec-actors">ğŸ‘· Autores</h2>

* Emanuel Lacerda - Desenvolvedor - [@EmanuelLacerda](https://github.com/EmanuelLacerda/)
* Matheus Juvelino - Consultor - [@matheusjuvelino-neon](https://github.com/matheusjuvelino-neon)

